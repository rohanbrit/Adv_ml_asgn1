{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b73469dc-aa4c-42b9-9df2-fa0f1afb4411",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning - Assignment 1\n",
    "### Rohan Rocky Britto - Student ID: 24610990"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0a8f45-2fbd-4f87-a631-5f88a52e47da",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d562598a-1c5b-4a74-a1d6-2cb06399bd0a",
   "metadata": {},
   "source": [
    "As per the Canvas discussions, I understood that the incorrect data in the height feature could be caused by Kaggle and/or Pandas. Hence, I have decided to reprocess the data all over again. I have also made some other changes to the pre-processing and hence, I will retry Random Forest first and then proceed with other algorithms for a fair comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb7bc3-3b49-4e46-a206-0c58269f9e0d",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75bd6b88-0254-47f0-bdd5-962b07a16660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040cb0d-c93a-4d62-b673-a1ff7e052d87",
   "metadata": {},
   "source": [
    "Read the raw data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd91429-1303-4a6d-95fd-b25ec678bd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_12644\\2000722632.py:1: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/raw/train.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/train.csv')\n",
    "df_test = pd.read_csv('../data/raw/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d20f7-8681-406e-9d43-6c58d26a744b",
   "metadata": {},
   "source": [
    "Copy the dataframe into a new dataframe for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b50dea-0e11-4e72-9b64-d8afbef1caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09df371-a942-4690-8c68-69edf6e3eacc",
   "metadata": {},
   "source": [
    "Move the target variable into a separate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662df102-c8c0-426c-94ab-facc7d40e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_cleaned.pop('drafted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde3915-dde4-48ec-a42c-0a843a3af892",
   "metadata": {},
   "source": [
    "We need to drop couple of features due to the following reasons:\n",
    "<br>&emsp;&emsp;1. Rec_Rank, dunks_ratio and pick columns have a lot of null values. Filling them up with mean values will lead to deviation from the real world data and hence, I have decided to drop them.\n",
    "<br>&emsp;&emsp;2. type feature has only 1 unique value and would not help the model in making predictions\n",
    "<br>&emsp;&emsp;3. num and player_id are identifiers and can lead to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e331a90f-26c8-4d1d-bb57-70116c618bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.drop(['Rec_Rank', 'dunks_ratio', 'pick', 'type', 'num', 'player_id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee9b4ac-5de9-4e80-9dc3-01c2fbfadf05",
   "metadata": {},
   "source": [
    "Create separate lists of columns with numerical and categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e735b6-04ad-4a29-8a2e-339cdc4f512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = list(df_cleaned.select_dtypes('number').columns)\n",
    "cat_cols = list(set(df_cleaned.columns) - set(num_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e183d1f4-52bc-4504-b6a0-929d4d9702b6",
   "metadata": {},
   "source": [
    "View the value count of categorical data before converting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb4fd184-9bd9-4382-9c61-619822801011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for yr :  yr\n",
      "Jr      14923\n",
      "Fr      14906\n",
      "So      13252\n",
      "Sr      12711\n",
      "0           5\n",
      "57.1        1\n",
      "42.9        1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for ht :  ht\n",
      "7-Jun     5578\n",
      "8-Jun     5498\n",
      "4-Jun     5363\n",
      "5-Jun     5353\n",
      "6-Jun     5126\n",
      "3-Jun     5125\n",
      "2-Jun     4648\n",
      "9-Jun     3988\n",
      "1-Jun     3539\n",
      "Jun-00    2984\n",
      "10-Jun    2491\n",
      "11-May    1518\n",
      "10-May    1378\n",
      "11-Jun    1119\n",
      "Jul-00     653\n",
      "9-May      598\n",
      "8-May      242\n",
      "-          241\n",
      "1-Jul      201\n",
      "7-May       95\n",
      "2-Jul       88\n",
      "3-Jul       40\n",
      "6-May       40\n",
      "Apr-00      20\n",
      "0           19\n",
      "4-Jul       11\n",
      "5-May        8\n",
      "6-Jul        7\n",
      "5-Jul        4\n",
      "4-May        4\n",
      "3-May        3\n",
      "2-May        3\n",
      "Jr           2\n",
      "1-May        2\n",
      "So           1\n",
      "Fr           1\n",
      "6'4          1\n",
      "5-Apr        1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for conf :  conf\n",
      "ACC     2297\n",
      "A10     2268\n",
      "SEC     2199\n",
      "B10     2123\n",
      "CUSA    2113\n",
      "MEAC    2027\n",
      "Slnd    2008\n",
      "BE      1977\n",
      "MAC     1914\n",
      "SB      1857\n",
      "SWAC    1775\n",
      "SC      1770\n",
      "OVC     1769\n",
      "BSth    1723\n",
      "B12     1714\n",
      "NEC     1690\n",
      "CAA     1640\n",
      "MAAC    1638\n",
      "BSky    1635\n",
      "Pat     1589\n",
      "MWC     1589\n",
      "MVC     1546\n",
      "Horz    1523\n",
      "P12     1501\n",
      "WCC     1491\n",
      "Ivy     1478\n",
      "ASun    1463\n",
      "BW      1435\n",
      "AE      1394\n",
      "Sum     1372\n",
      "WAC     1347\n",
      "Amer    1047\n",
      "ind      429\n",
      "P10      415\n",
      "GWC      324\n",
      "Ind       11\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for team :  team\n",
      "Army                   209\n",
      "Air Force              202\n",
      "Cornell                199\n",
      "Arkansas Pine Bluff    198\n",
      "Navy                   196\n",
      "                      ... \n",
      "Centenary               40\n",
      "Winston Salem St.       30\n",
      "Cal Baptist             25\n",
      "North Alabama           25\n",
      "Merrimack               11\n",
      "Name: count, Length: 358, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    print('Value counts for', col, ': ', df_cleaned[col].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97004ce-d341-4a23-a80d-7ce19445b45f",
   "metadata": {},
   "source": [
    "Replace abnormalities in yr feature with mode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c5114b2-1fec-4d7c-8c8f-f3b062f68d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_yr_values = ['So', 'Sr', 'Jr', 'Fr']\n",
    "df_cleaned['yr'].replace(list(set(df_cleaned['yr'].unique()) - set(valid_yr_values)),df_cleaned['yr'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16931d-1f21-4be2-88d2-12d91cbc16c7",
   "metadata": {},
   "source": [
    "Replace abnormalities in ht feature with mode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b16b1213-aeba-4393-bc02-de9ffb2303b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '^(\\d{1,2}-[A-Z][a-z]{2})|([A-Z][a-z]{2}-\\d{1,2})$'\n",
    "replacement = df['ht'].mode()[0]\n",
    "\n",
    "def replace_non_matching(item):\n",
    "    return item if re.match(pattern, str(item)) else replacement\n",
    "\n",
    "df_cleaned['ht'] = df_cleaned['ht'].apply(replace_non_matching)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e1388-f6da-417a-acf9-3a1ca7792440",
   "metadata": {},
   "source": [
    "Create a list of columns having null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dedd6e9b-232d-469e-b7be-8621a673fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cols = list(df_cleaned.columns[df_cleaned.isnull().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f98bef-db71-426d-879d-526c70cd37bf",
   "metadata": {},
   "source": [
    "Replace null values with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d16bfa9-df23-40b7-afc0-06b697645847",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in null_cols:\n",
    "    if col in num_cols:\n",
    "        df_cleaned[col].fillna(df_cleaned[col].mean(), inplace=True)\n",
    "    else:\n",
    "        df_cleaned[col].fillna(df_cleaned[col].mode(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a93bc7-bfd4-412b-b43f-7c0644780750",
   "metadata": {},
   "source": [
    "Define a function for processing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6f81e2f-0274-4552-8c6b-78826012b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df_data):\n",
    "    pattern = '^(\\d{1,2}-[A-Z][a-z]{2})|([A-Z][a-z]{2}-\\d{1,2})$'\n",
    "    replacement = df['ht'].mode()[0]\n",
    "    def replace_non_matching(item):\n",
    "        return item if re.match(pattern, str(item)) else replacement\n",
    "    df_data['ht'] = df_data['ht'].apply(replace_non_matching)\n",
    "\n",
    "    df_data.drop(['Rec_Rank', 'dunks_ratio', 'pick', 'type', 'num', 'player_id'], inplace=True, axis=1)\n",
    "    valid_yr_values = ['So', 'Sr', 'Jr', 'Fr']\n",
    "    df_data['yr'].replace(list(set(df_data['yr'].unique()) - set(valid_yr_values)),df_data['yr'].mode()[0], inplace=True)\n",
    "    \n",
    "    null_cols = list(df_data.columns[df_data.isnull().any()])\n",
    "    for col in null_cols:\n",
    "        if col in num_cols:\n",
    "            df_data[col].fillna(df_data[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df_data[col].fillna(df_data[col].mode(), inplace=True)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06348ef9-3416-4979-aade-715772d5ee89",
   "metadata": {},
   "source": [
    "Import joblib to save models for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a7a1ca-771e-4442-9556-7e8de63dc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a4a19f9-a4fb-4f16-86a4-4165ddecf6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../src/models/process_data.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(process_data, '../src/models/process_data.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ded2e0-d7ca-49d9-bc66-254c2c9f1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cleaned = df_test.copy()\n",
    "df_test_cleaned = process_data(df_test_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3091b443-b196-4e3e-a2f7-557c9cf0587f",
   "metadata": {},
   "source": [
    "We will use Frequency Encoding as they have a lot of values. Transforming categorical features with a lot of values using OneHot Encoding can lead to Dimensionality crisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b0c0e7-9afe-4a60-98aa-28ad8413fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.encoding import CountFrequencyEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c80763a6-3b93-4569-9bfa-46df41ba5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqenc = CountFrequencyEncoder(encoding_method='frequency', variables=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8346cc9-0beb-4a21-a63a-ebc197a01327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\adv-ml-asgn1-Z8OfE-WH-py3.11\\Lib\\site-packages\\feature_engine\\encoding\\base_encoder.py:257: UserWarning: During the encoding, NaN values were introduced in the feature(s) team.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "features = freqenc.fit_transform(df_cleaned[cat_cols])\n",
    "X_test = freqenc.transform(df_test_cleaned[cat_cols])\n",
    "X_test.fillna(0.0001, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9f8e70c-2d1f-44b2-9ffe-3c572543d5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/freqenc.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(freqenc, '../models/freqenc.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b88b8f4-a956-4f46-b291-928e45e22233",
   "metadata": {},
   "source": [
    "Scaling the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa44d434-d229-416d-b43a-41ccd00f7e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load('../models/scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe21ce50-f0be-47f3-a976-1f35e3d9b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[num_cols] = scaler.fit_transform(df_cleaned[num_cols])\n",
    "X_test[num_cols] = scaler.transform(df_test_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cccb5d-5ce0-44d4-9bfe-e53d5201a9bf",
   "metadata": {},
   "source": [
    "Let us check the class balance in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e274b2b9-3b79-4f23-b597-298cb58dda75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drafted\n",
       "0.0    55555\n",
       "1.0      536\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3821b-0bf8-4d97-9a23-adfa33b50969",
   "metadata": {},
   "source": [
    "The dataset looks very imbalanced. We will balance it using SMOTE to a 1:10 ratio so that it does not deviate very much from the real world scenario but also reduces model bias towards one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29f0b0ee-5222-4002-a997-bbf5b8109ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "431e2d05-04bc-4dce-9d45-8c7b6f6ed4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=8, sampling_strategy=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c37e5948-7171-4494-95b0-a0bf0e18247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = sm.fit_resample(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8aada850-6bfb-4b28-996f-216817a5365a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/sm.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(sm, '../models/sm.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56cd540-7223-4167-94dc-3cb2f5f5da4b",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc820e3-56e9-4c26-ab8d-ee327fa3e28b",
   "metadata": {},
   "source": [
    "As the testing dataset is separate, I have decided to split the dataset into 80:20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e1d6f59-a247-4a3e-9ca7-f0700cd687b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d9f9016-7085-499d-9162-b05f5b8f99f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features, target, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40edf157-f47f-4192-9ebb-d1b0706a4415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48888, 57)\n",
      "(12222, 57)\n",
      "(4970, 57)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13e22302-a375-4fa8-b1b9-62ff677b6d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48888,)\n",
      "(12222,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab44de0d-6e15-470e-a7db-b077ffb0c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../data/processed/X_train.csv')\n",
    "X_val.to_csv('../data/processed/X_val.csv')\n",
    "X_test.to_csv('../data/processed/X_test.csv')\n",
    "y_train.to_csv('../data/processed/y_train.csv')\n",
    "y_val.to_csv('../data/processed/y_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a96345-0842-474e-a3ad-6c26a5fb147f",
   "metadata": {},
   "source": [
    "## Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a3b42ba-4ac1-4cde-a235-50a05a546a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1048d-09a3-4629-b140-a5de2c9d9291",
   "metadata": {},
   "source": [
    "Define fit_predict_proba function to fit, predict probability and evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a018318a-53f8-44b8-a87a-c1bcd2ac37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_proba(model, X_train, y_train, X_val, y_val):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred_prob = model.predict_proba(X_train)[:,1]\n",
    "    y_val_pred_prob = model.predict_proba(X_val)[:,1]\n",
    "    print('The AUROC value for the training set is: ', roc_auc_score(y_train, y_train_pred_prob))\n",
    "    print('The AUROC value for the validation set is: ', roc_auc_score(y_val, y_val_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007fd2f7-617a-45ad-a39d-a2d8ed16e317",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5196abc-2bc9-4adf-92ac-3e497e5ebd05",
   "metadata": {},
   "source": [
    "We will use Random Forest Classifier as our prediction model and evaluate its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10d61fb7-9896-435b-b0e9-e7464c1b1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4562f67-2531-4690-89f3-97944b4d6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "964c9889-0796-4ea0-a5ba-568b9cad243b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUROC value for the training set is:  1.0\n",
      "The AUROC value for the validation set is:  0.9991044346553366\n"
     ]
    }
   ],
   "source": [
    "fit_predict_proba(rf1, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd85135-70ea-4791-9ee2-5fc60caf1119",
   "metadata": {},
   "source": [
    "The model seems to be slightly overfitting. Let us adjust some hyperparameters to reduce it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7887fc20-5bef-4567-814a-cb749e4ab82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(max_depth=8, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fd6b56d-c1ff-476f-9d46-ac55caa650b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUROC value for the training set is:  0.9979623012261046\n",
      "The AUROC value for the validation set is:  0.9960464614286201\n"
     ]
    }
   ],
   "source": [
    "fit_predict_proba(rf2, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e49f5-983d-46e6-9c80-3e89275a21e8",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fb09606-0da4-41ca-ad24-99e9c70aa7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52b3a03e-712e-4a7b-b7b1-c3b848a84986",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression(random_state=8, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d249d5c-e204-4a25-b260-8cf6d2670e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUROC value for the training set is:  0.9905439790025555\n",
      "The AUROC value for the validation set is:  0.9908248144165317\n"
     ]
    }
   ],
   "source": [
    "fit_predict_proba(lr1, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012c88c-18a7-4ed6-b1d0-8ad64d2aaa9a",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a410eb1-c60e-4296-bafd-313b54ffcc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05449d38-5552-452f-8f8a-eddeeaae18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc1 = SVC(random_state=8, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10b808ad-abda-45df-a040-1d84aedb29d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUROC value for the training set is:  0.9958669446502685\n",
      "The AUROC value for the validation set is:  0.9953452326611877\n"
     ]
    }
   ],
   "source": [
    "fit_predict_proba(svc1, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b567d-dae3-4394-8361-ab2ea8404d07",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85020bcc-8aa3-434e-97a3-bcec6b6e3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65da9815-3263-4e0f-9c86-aad94372d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost1 = AdaBoostClassifier(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36046262-f18a-48bb-9c2b-d66b9cf6c943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUROC value for the training set is:  0.9965946779711462\n",
      "The AUROC value for the validation set is:  0.9960520967401683\n"
     ]
    }
   ],
   "source": [
    "fit_predict_proba(adaboost1, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e447d-92ca-4810-9164-943c492cbc97",
   "metadata": {},
   "source": [
    "## Testing and submission file preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace861ff-9b40-432b-af44-5633110abf22",
   "metadata": {},
   "source": [
    "I have moved the top two best performing models to the a different variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dd6c9ec-91e6-420b-834c-6fe7053379d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = adaboost1\n",
    "model2 = svc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f02198e4-b079-457b-968c-57eaa0ea8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission1 = pd.DataFrame({})\n",
    "df_submission2 = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a773247-9b13-4546-89cc-69f9db96d242",
   "metadata": {},
   "source": [
    "Add the player ID from the testing dataset to the submission dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a29521ef-e841-4992-968a-7e8b0626e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission1['player_id'] = df_test['player_id']\n",
    "df_submission2['player_id'] = df_test['player_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18f7dd-d170-4e95-a3d6-d5e40e86b81e",
   "metadata": {},
   "source": [
    "Add the prediction probability to the drafted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57701eb6-8c08-4b44-97f5-ccb4067b8387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission1['drafted'] = model1.predict_proba(X_test)[:,1]\n",
    "df_submission2['drafted'] = model2.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c901bd6-0380-44f6-8df2-633fa2d36772",
   "metadata": {},
   "source": [
    "Save the dataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c56e8a0-d2d4-49ae-86cc-cdb79e9d0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission1.to_csv('../data/processed/submission1.csv', index=False)\n",
    "df_submission2.to_csv('../data/processed/submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf6de1-8905-4bda-bd65-1ee2e565666e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
